== Building a Pipeline

== Overview

This section will build upon your use of Jupyter notebooks, and expand your knowledge by building a reusable pipeline that runs all three notebooks in succession to create and deploy the newly trained model out to an "edge" environment.

NOTE:  As a reminder in this overall lab module we are focusing on the user experience and flow of training a model and making it available to be used, or operationalized.  In the next Module: Application Services AppDev we will focus more on how to call those models and run end to end data pipelines.


In this section, each of you will:

* Revisit the notebooks your worked with in a prior section.
* Create an Elyra pipeline using a visual editor.
* Export the Elyra pipeline as a yaml representation.
* Create an OpenShift Pipeline that implements the Jupyter based Elyra pipeline yaml export.
* Run the OpenShift pipeline and test it.




* First you need ensure you are still have browser tabs logged into OpenShift AI and your Data Science Project. Also ensure you have a Jupyter environment open.  If you don't, or are having connection issues, review the following guidance and skip to step that fits your situation.

xref:includes/02-ocp-re-open-ocpai.adoc[Re/Open OpenShift AI Project]


























NOTE:  Although the processing/training of models may seem to take some time, we are only using a small sample set of images for this lab to simplify setup and reduce waiting time for lab participants. In a real-world scenario you would be loading a lot more images for training and the overall prediction accuracy would increase.

