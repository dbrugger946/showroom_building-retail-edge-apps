== Building a Pipeline

== Overview

This section will build upon your use of Jupyter notebooks, and expand your knowledge by building a reusable pipeline that runs all three notebooks in succession to create and deploy the newly trained model out to an "edge" environment.

NOTE:  As a reminder in this overall lab module we are focusing on the user experience and flow of training a model and making it available to be used, or operationalized.  In the next Module: Application Services AppDev we will focus more on how to call those models and run end to end data pipelines.


In this section, each of you will:

* Revisit the notebooks your worked with in a prior section.
* Create an Elyra pipeline using a visual editor.
* Export the Elyra pipeline as a yaml representation.
* Create an OpenShift Pipeline that implements the Jupyter based Elyra pipeline yaml export.
* Run the OpenShift pipeline and test it.




* First you need ensure you are still have browser tabs logged into OpenShift AI and your Data Science Project. Also ensure you have a Jupyter environment open.  If you don't, or are having connection issues, review the following guidance.

xref:includes/02-ocp-re-open-ocpai.adoc[Re/Open OpenShift AI Project]


== Steps

* Once you are inside/back inside your Workbench Jupyter Environment you should be at the *workbench* directory you were working in previously.

[.bordershadow]
image::01-06/01-dir1.png[width=75%]

** If you are NOT there an easy way to navigate to it is to click on the the Left most folder icon in the top of the navigation pane.  _This will work from no matter where you are in the directory structure._

[.bordershadow]
image::01-06/02-dir.png[width=75%]

** It will take you to your base directory.
[.bordershadow]
image::01-06/03-dir.png[width=75%]

** Double click on *edge-to-cloud-pipelines-workshop* and then double click on *workbench*

[.bordershadow]
image::01-06/03-dir.png[width=75%]

[.bordershadow]
image::01-06/04-dir.png[width=75%]

** You should now be back in the workbench directory with the jupyter notebooks

[.bordershadow]
image::01-06/05-dir.png[width=75%]


* Create an Elyra based pipeline
** Scroll down the Launcher window and click on the *Pipeline Editor* under Elyra.

[.bordershadow]
image::01-06/06-Elyra.png[width=75%]

[.bordershadow]
image::01-06/07-Elyra.png[width=75%]

** In the navigation pane on the Left, Right click on the pipeline and rename it to *{user}.pipeline*
** Save it.

[.bordershadow]
image::01-06/08-Elyra-rename.png[width=75%]

[.bordershadow]
image::01-06/09-Elyra-save.png[width=75%]

* Now you will drag and drop the 3 notebooks over onto the pipeline editor screen.  As seen here

[.bordershadow]
image::01-06/10-create-pipeline1.png[width=75%]





























NOTE:  Although the processing/training of models may seem to take some time, we are only using a small sample set of images for this lab to simplify setup and reduce waiting time for lab participants. In a real-world scenario you would be loading a lot more images for training and the overall prediction accuracy would increase.

